---
title: "failure-svn"
author: "Doug McNeall"
date: "9/8/2023"
output: html_document
---

This script build a Support Vector Machine that predicts run status of the JULES-ES-1.0 ensemble. Can you make a better classifier?

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}

set.seed(42)

library(RColorBrewer)
library(e1071)
library(MASS)
library(caret)

```



```{r}
load('data/wave0_summary.RData')

```

```{r}
ix_train <- 1:399
ix_test <- 400:499

train <- cbind(wave0_summary_df[ix_train, 1:32], wave0_summary_df[ix_train, 'Y_char'] )
test <- cbind(wave0_summary_df[ix_test, 1:32], wave0_summary_df[ix_test, 'Y_char'] )


colnames(train) <- c(colnames(wave0_summary_df)[1:32], 'run_status')
colnames(test) <- c(colnames(wave0_summary_df)[1:32], 'run_status')

```


## Simple non-probabilistic SVM classifier, using two known-important inputs

The classifier is much worse if we include all the inputs.

```{r}
train_x <- train[, c(8,4)]
train_y <- train[, 33]

class(train_x) <- 'numeric'

test_x <- test[, c(8,4)]
test_y <- test[, 33]

class(test_x) <- 'numeric'
```


```{r}
svm_fit<- svm(train_x, as.factor(train_y),  probability = FALSE)
svm_pred <- predict(svm_fit, newdata=test_x, probability = FALSE)


```


```{r}
# Evaluate the model

confusionMatrix(svm_pred, as.factor(test_y))


```

## Plot the non-probabilistic SVM.

We don't predict any crashes, which might need looking at. Accuracy is 0.84, which feels like it might be improved.
```{r, fig.width = 7, fig.height = 7}

upper <- apply(train_x, 2, max)
lower <- apply(train_x, 2, min)

x1_seq <- seq(from=lower[1], to=upper[1], length.out = 50)
x2_seq <- seq(from=lower[2], to=upper[2], length.out = 50)

# A grid of test points that covers the entire data space
test_grid <- as.matrix(expand.grid(x1_seq, x2_seq))
colnames(test_grid) <- colnames(train_x)

svm_pred_grid <- predict(svm_fit, newdata=test_grid, probability = FALSE)


pal <- c('red', 'blue','grey')
par(las = 1, cex = 1.3)
plot(test_grid, col = pal[svm_pred_grid], pch = 20, cex = 0.8, main = 'SVM classifier prediction')

points(train_x, bg = pal[as.factor(train_y)], cex = 1, pch =21)

legend('topleft', legend = unique(as.factor(train_y)),
pt.bg = pal[unique(as.factor(train_y))],
pch = 21,
col = 'black',
text.col= pal[unique(as.factor(train_y))],
 bg = 'white',
cex = 0.8)
```


